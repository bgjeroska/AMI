{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models - Partial Least Squares Regression and the LASSO\n",
    "#### a.k.a. Review vs. Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and show dataset\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('svg')\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we try to predict the revenue of a movie based on its reviews using the __Rotten Tomato Movie Review Dataset__ (http://users.stat.ufl.edu/~winner/datasets.html)\n",
    "\n",
    "Variables:\n",
    "- Rank   \n",
    "- AllPos    (# Positive Reviews among all critics)\n",
    "- AllNeg    (# Negative Reviews among all critics)\n",
    "- TopPos    (# Positive Reviews Among Top critics)\n",
    "- TopNeg    (# Negative Reviews Among Top critics)\n",
    "- PropAllPos  (Proportion Positive Reviews among all critics)\n",
    "- PropTopPos  (Proportion Positive Reviews among top critics)\n",
    "- Movie\n",
    "- Release     (Date of Release)\n",
    "- Rev_10M     (revenue, in $10Ms)\n",
    "- year        (year of Release)\n",
    "- AllFresh    (1 if PropAllPos >= 0.60, 0 otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Data Inspection and Preprocessing\n",
    "When we load the data and examine the types, we notice that the release date is encoded as a string. We are not dealing with a Time Series problem here, so we cannot easily use the date in our model. Therefore we split the date into day, month and year. In addition, we calculate a kind of relative date by setting each release in relation to the oldest release. We also have to fix that `PropTopPos` is an object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('box_office_rt.csv')\n",
    "data['Release'] = pd.to_datetime(data.Release) #convert the string object Release to datetime datatype\n",
    "data['month'] = data.Release.dt.month\n",
    "data['day'] = data.Release.dt.day\n",
    "data['rel_release'] = data.Release.subtract(data.Release.min()) \n",
    "data['rel_release'] = data.rel_release.dt.total_seconds()/(3600*24) #release relative to the 1st entry (in days)\n",
    "print(data.PropTopPos[(data.TopPos==0) & (data.TopNeg==0)]) #print wrong/missing values\n",
    "data['PropTopPos'] = pd.to_numeric(data['PropTopPos'], errors='coerce') #convert variable to numeric - \"#DIV/0\" will be set to NaN\n",
    "print(data.PropTopPos[(data.TopPos==0) & (data.TopNeg==0)]) #print NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()[(data.isnull().sum() > 0)] #check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the line of code below to perfrom scatter plots of variables which are of your interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Rank', y='Rev_10M',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Rev_10M','Rank', 'Movie','Release'])\n",
    "y = data.Rev_10M\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.33, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we see a good correlation of `Rank` with `Rev_10m` for an unknown film, we would not yet have the information about the `Rank` based on the revenue, since we would have to calculate it first. Therefore, we will not use this variable. We will also drop the variable `Movie` and the datetime-formatted `Release`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the correlation matrix below. (Code snippet taken from [seaborn docs](https://seaborn.pydata.org/examples/many_pairwise_correlations.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(data.loc[X_train.index].corr(), dtype=bool))\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(data.loc[X_train.index].corr(), mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Partial Least Squares Regression\n",
    "We encoutered 4 missing values which we have to take care of. The easiest and simplest solution is to intergrate a `SimpleImputer` in the Pipeline. It fills the missing values with the column mean. As an initial model - we fit a PLS regression on the training set using 3 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xscaler = StandardScaler()\n",
    "yscaler = StandardScaler()\n",
    "pipe = Pipeline([('imputer', SimpleImputer()),('scaler', xscaler), ('plsr', PLSRegression(n_components=3))])\n",
    "model = TransformedTargetRegressor(regressor=pipe, transformer=yscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the X-scores (the \"new\" latent X-variables) to the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = model.regressor_['plsr'].x_scores_\n",
    "data_pls = pd.DataFrame(columns=X_train.columns,data=xscaler.fit_transform(X_train))\n",
    "data_pls[['T1', 'T2', 'T3']] = pd.DataFrame(T)\n",
    "data_pls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we observe the scores plot of the first and second component, we integrate the information about the revenue by color. The outcome is a bit indifferent. We can not see clear clusters and we can also not see a clear relationship between the revenue and the X-scores. We can see that the highest grossing movies (very dark color) are not lying close together in the T1-T2-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(x='T1',y='T2',hue=(yscaler.fit_transform(y_train.values.reshape(-1,1))).ravel(), data=data_pls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conterpart to scores plots in PCA/PLSR domain, are the so called loadings plots. Also scatter plots, but now we plot the loadings which are used to transform the oroginal variables to their new latent space. We can use loading plots to interpret which features contrubute to the components. The problem with loading plots is the scaling. Interpretation is easier by using so called correlation loadings. The correlation loadings are bounded between -1 and 1 and thus easier to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = model.regressor_['plsr'].x_loadings_[:,0],y=model.regressor_['plsr'].x_loadings_[:,1])\n",
    "plt.xlabel('P1')\n",
    "plt.ylabel('P2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation loadings can be calculeted directly from the loadings or by computing the pearson correlation coefficient between the oroginal features and the scores. We will use the latter approach, as pandas gives us the pairwise correlations with a single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corL = data_pls.corr()\n",
    "corL.drop(corL.columns[:-3],axis=1,inplace=True)\n",
    "corL.drop(corL.index[-3:],axis=0,inplace=True)\n",
    "corL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can again go for the correlation loadings plot. We also add the circles of 50% variance and 100% variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='T1', y='T2', data=corL)\n",
    "plt.plot(np.sin(np.linspace(0,2*np.pi,100)),np.cos(np.linspace(0,2*np.pi,100)),'--',color='.5')\n",
    "plt.plot(np.sqrt(0.5)*np.sin(np.linspace(0,2*np.pi,100)),np.sqrt(.5)*np.cos(np.linspace(0,2*np.pi,100)), '--', color='.8')\n",
    "for kk,nme in enumerate(corL.index):\n",
    "     plt.annotate(nme,(corL.T1.values[kk]+.01,corL.T2.values[kk]))\n",
    "plt.ylim(-1.1,1.1)\n",
    "plt.xlim(-1.1,1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `rel_release` and `TopPos` and  `AllPos` are pretty much exactly on the direction of the first component. Whereas `rel_release` is only  weakly correlated (i.e., close to the origin), the other two features contribute very strongly (positively) to the first component. \n",
    "`month` is slightly positively associated with the second component, whereas `TopNeg` and `AllNeg` are negatively correlated with it. \n",
    "The percentage features, as well as `AllFresh` put one are around 45 degrees, the release year at -45 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(x='T1', y='T3', data=corL)\n",
    "plt.plot(np.sin(np.linspace(0,2*np.pi,100)),np.cos(np.linspace(0,2*np.pi,100)),'--',color='.5')\n",
    "plt.plot(np.sqrt(0.5)*np.sin(np.linspace(0,2*np.pi,100)),np.sqrt(.5)*np.cos(np.linspace(0,2*np.pi,100)), '--', color='.8')\n",
    "for kk,nme in enumerate(corL.index):\n",
    "     plt.annotate(nme,(corL.T1.values[kk]+.01,corL.T3.values[kk]))\n",
    "plt.ylim(-1.1,1.1)\n",
    "plt.xlim(-1.1,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not see any excessively strong correlations for the third component. We that `day` is nagatively correlated and a slightly stronger correlation is observed with `rel_release`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(x='T2', y='T3', data=corL)\n",
    "plt.plot(np.sin(np.linspace(0,2*np.pi,100)),np.cos(np.linspace(0,2*np.pi,100)),'--',color='.5')\n",
    "plt.plot(np.sqrt(0.5)*np.sin(np.linspace(0,2*np.pi,100)),np.sqrt(.5)*np.cos(np.linspace(0,2*np.pi,100)), '--', color='.8')\n",
    "for kk,nme in enumerate(corL.index):\n",
    "     plt.annotate(nme,(corL.T2.values[kk]+.01,corL.T3.values[kk]))\n",
    "plt.ylim(-1.1,1.1)\n",
    "plt.xlim(-1.1,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have worked with an initial estimate of the number of compnents to address the specifics of PLS (Scores and loadings plot). In many textbooks only 2 components are often used for visualization and interpretation. However, we will of course perform a grid search to determine the number of components that gives us the smallest RMSE. The nice thing about PLSR is that the parameter space is discrete and constrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cval = KFold(10, random_state=60, shuffle=True)\n",
    "pipe1 = Pipeline([('imputer', SimpleImputer()),('scaler', xscaler), ('plsr', PLSRegression(n_components=3))])\n",
    "model1 = TransformedTargetRegressor(regressor=pipe1, transformer=yscaler)\n",
    "param_grid1 = dict()\n",
    "param_grid1['regressor__plsr__n_components'] = np.arange(1,X_train.shape[1])\n",
    "search1 = GridSearchCV(model1, param_grid1, scoring=['neg_root_mean_squared_error','r2'], n_jobs=-1, cv=cval, refit='neg_root_mean_squared_error', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search1.fit(X_train,y_train)\n",
    "results1 = pd.DataFrame(search1.cv_results_)\n",
    "print(\"Best parameter RMSE=%0.3f):\" % (-search1.best_score_))\n",
    "print(search1.best_params_)\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(results1.param_regressor__plsr__n_components, -results1.mean_train_neg_root_mean_squared_error, yerr=results1.std_train_neg_root_mean_squared_error, label='Train')\n",
    "plt.errorbar(results1.param_regressor__plsr__n_components, -results1.mean_test_neg_root_mean_squared_error, yerr=results1.std_test_neg_root_mean_squared_error, label = 'Test (CV)')\n",
    "plt.legend()\n",
    "plt.xlabel(\"# of components\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"PLSR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe a quite high variance for each of the components and we can also see that more components than initially guessed are neccessary for the lowest RMSE in out setting. It is interesting to observe that for more than 5 coponents we run into overfitting (decreasing RMSE (train) and increasing RMSE (test)). Furthermore we have to state that the RMSE is quite high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lasso Regresison\n",
    "As a representative of the regularizing models we choose Lasso. The difference to ridge regression is the norm of the coefficient vector. In this case, the $l_1$ norm is used, which favors a sparse coefficient vector. This implicitly performs a feature selection - non-relevant features are set to 0. However, if there are several strongly correlated (but \"important\") variables, one may be selected and the others set to zero. The parameter we want to tune via gridsearch is the weight for your constraint for the $l_1$ norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([('imputer', SimpleImputer()),('scaler', xscaler), ('lasso', Lasso())])\n",
    "model2 = TransformedTargetRegressor(regressor=pipe2, transformer=yscaler)\n",
    "param_grid2 = {'regressor__lasso__alpha': [1e-9,1e-3,5e-3,8e-3, 1e-2,2e-2,3e-2, 8e-2,1e-1,1]}\n",
    "search2 = GridSearchCV(model2, param_grid2, scoring=['neg_root_mean_squared_error','r2'], n_jobs=-1, cv=cval, refit='neg_root_mean_squared_error', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search2.fit(X_train, y_train)\n",
    "print(\"Best parameter RMSE=%0.3f):\" % (-search2.best_score_))\n",
    "print(search2.best_params_)\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(param_grid2['regressor__lasso__alpha'],-search2.cv_results_['mean_train_neg_root_mean_squared_error'],yerr=search2.cv_results_['mean_train_neg_root_mean_squared_error'],label='Train')\n",
    "plt.errorbar(param_grid2['regressor__lasso__alpha'],-search2.cv_results_['mean_test_neg_root_mean_squared_error'],yerr=search2.cv_results_['mean_test_neg_root_mean_squared_error'],label='Test')\n",
    "plt.gca().set_xscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Lasso\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that moderate regularization leads to the best results. When alpha approaches zero, the model approaches a \"normal\" linear regression. For larger alpha values, the RMSE deteriorates significantly. The error is in a similar range as for PLSR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Final Performance\n",
    "Finally we will asses the performance on the held out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator1 = search1.best_estimator_\n",
    "y_pred_train1 = best_estimator1.predict(X_train)\n",
    "y_pred_test1 = best_estimator1.predict(X_test)\n",
    "best_estimator2 = search2.best_estimator_\n",
    "y_pred_train2 = best_estimator2.predict(X_train)\n",
    "y_pred_test2 = best_estimator2.predict(X_test)\n",
    "\n",
    "\n",
    "minlim = np.min([y_test.min(), np.min(y_pred_test1), np.min(y_pred_test2)])-1\n",
    "maxlim = np.max([y_test.max(), np.max(y_pred_test1), np.max(y_pred_test2)])+1\n",
    "# predicted/actual plot for test set\n",
    "ax = sns.jointplot(x=y_test.ravel(),y=y_pred_test1.ravel(), height=5,xlim=(minlim,maxlim),ylim=(minlim,maxlim))\n",
    "ax.ax_joint.set_xlabel('observed player performance')\n",
    "ax.ax_joint.set_ylabel('predicted player performance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# predicted/actual plot for test set\n",
    "ax = sns.jointplot(x=y_test.ravel(),y=y_pred_test2.ravel(), height=5,xlim=(minlim,maxlim),ylim=(minlim,maxlim))\n",
    "ax.ax_joint.set_xlabel('observed player performance')\n",
    "ax.ax_joint.set_ylabel('predicted player performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortuenately the diagnostic plots above look not very promising - so, what is it at least good for? Let's compare our models to the simplest linear model, aka linear regression as well as a dummy estimator. The latter serves as a worst case estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### lr baseline\n",
    "pipelr = Pipeline([('imputer', SimpleImputer()),('scaler', xscaler), ('lr', LinearRegression())])\n",
    "modellr = TransformedTargetRegressor(regressor=pipelr, transformer=yscaler)\n",
    "modellr.fit(X_train,y_train)\n",
    "\n",
    "### dummy worst case\n",
    "pipedm = Pipeline([('imputer', SimpleImputer()),('scaler', xscaler), ('dm', DummyRegressor())])\n",
    "modeldm = TransformedTargetRegressor(regressor=pipedm, transformer=yscaler)\n",
    "modeldm.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "est = {'PLSR': best_estimator1, 'Lasso': best_estimator2, 'LinReg': modellr, 'Dummy': modeldm}\n",
    "\n",
    "fin_res = pd.DataFrame({'model': ['PLSR', 'Lasso','LinReg', 'Dummy'], 'RMSE train': np.empty(4), 'R2 train': np.empty(4), 'RMSE test': np.empty(4), 'R2 test': np.empty(4)}).set_index('model')\n",
    "\n",
    "for m in ['PLSR', 'Lasso', 'LinReg','Dummy']:\n",
    "    y_pred_train = est[m].predict(X_train)\n",
    "    y_pred_test = est[m].predict(X_test)\n",
    "    fin_res.at[m,'RMSE train'] = np.sqrt(mean_squared_error(y_train,y_pred_train))\n",
    "    fin_res.at[m,'R2 train'] = r2_score(y_train,y_pred_train)\n",
    "    fin_res.at[m,'RMSE test'] = np.sqrt(mean_squared_error(y_test,y_pred_test))\n",
    "    fin_res.at[m,'R2 test'] = r2_score(y_test,y_pred_test)\n",
    "fin_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lasso outperforms all other approaches, but we can not see huge differences. Even if we would build no model at all (=Dummy) we achieve a RMSE of approx. 70 million dollars. In this case we would have a hard time to sell this model. It seems that we are missing some important predictors. You can at least check if a more flexible, non-linear model would perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step, we compare the coefficients from different models. We should also be able to see that the LASSO leads to coefficients equal to 0. The coefficients will be ranked according to their magnitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,axs = plt.subplots(1,3, figsize=(8,3))\n",
    "coef1 = pd.Series(best_estimator1.regressor_['plsr'].coef_.ravel(), index = X_train.columns).sort_values(key=lambda x: np.abs(x))\n",
    "coef2 = pd.Series(best_estimator2.regressor_['lasso'].coef_, index = X_train.columns).sort_values(key=lambda x: np.abs(x))\n",
    "coef3 = pd.Series(modellr.regressor_['lr'].coef_, index = X_train.columns).sort_values(key=lambda x: np.abs(x))\n",
    "\n",
    "coef1.plot(kind = \"barh\",ax = axs[0])\n",
    "axs[0].set_title(\"Coefficients PLSR\")\n",
    "axs[0].set_xlim(-.4,1)\n",
    "\n",
    "coef2.plot(kind = \"barh\",ax = axs[1])\n",
    "axs[1].set_title(\"Coefficients Lasso\")\n",
    "axs[1].set_xlim(-.4,1)\n",
    "\n",
    "coef3.plot(kind = \"barh\",ax = axs[2])\n",
    "axs[2].set_title(\"Coefficients LinReg\")\n",
    "axs[2].set_xlim(-.4,1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
